---
title: "Projeto Estatística"
toc: true
---

## 1. Introdução

Neste projeto, será realizado uma análise estatística com o objetivo de investigar possíveis relações entre fatores, como, por exemplo, idade, horas de estudo, e como impactam o desempenho acadêmico de um estudante.

```{r}
# Instala biblioteca caso necessário 
if (!require(readxl)) install.packages("readxl") 
# Importando biblioteca para ler arquivo .xslx 
library(readr) 
# Lendo base de dados 
dados <- read_xlsx("base_de_dados.xlsx")
```

## 2. A Base de Dados

A base de dados é composta por 943 observações e 9 variáveis, cada uma representando uma característica ou comportamento relacionado ao desempenho escolar. Abaixo estão listadas as variáveis investigadas, seus significados e respectivas unidades de medida:

1.  Idade

    -   Tipo: Quantitativa

    -   Descrição: Indica a idade do aluno

    -   Unidade de medida: Anos

2.  Horas de estudos

    -   Tipo: Quantitativa

    -   Descrição: Indica o tempo total de estudo de um aluno

    -   Unidade de medida: Horas

3.  Frequência

    -   Tipo: Quantitativa

    -   Descrição: Representa a frequência do aluno nas aulas

    -   Unidade de Medida: Percentual (%)

4.  Atividades extracurriculares

    -   Tipo: Categórica

    -   Descrição: Indica se o aluno participa de atividades extracurriculares

    -   Unidade de medida: Pode ser Sim/Não

5.  Nível socioeconômico

    -   Tipo: Categórica

    -   Descrição: Representa a condição econômica e social do aluno

    -   Unidade de medida: Pode ser Alto/Médio/Baixo

6.  Motivação

    -   Tipo: Quantitativa

    -   Descrição: Mede o nível de motivação do aluno em relação aos estudos

    -   Unidade de medida: Percentual (%)

7.  Notas anteriores

    -   Tipo: Quantitativa

    -   Descrição: Refere-se ao desempenho escolar (média) de um aluno em avaliações escolares

    -   Unidade de medida: Nota numérica (de 0 a 10)

8.  Sono

    -   Tipo: Quantitativa

    -   Descrição: Indica o tempo médio de sono diário de um aluno

    -   Unidade de medida: Horas

9.  Desempenho

    -   Tipo: Quantitativa

    -   Descrição: Refere-se ao desempenho escolar de um aluno

    -   Unidade de medida: Percentual (%)

Sumário da base de dados:

```{r}
if (!require(skimr)) install.packages("skimr")
library(skimr)
skim(dados)

```

### 2.1 Valores Ausentes

Com base na tabela de análise exploratória gerada, podemos identificar que 8 observações da base de dados não possuem a variável notas anteriores. Além disso, também podemos verificar que a variável horas de estudo não está presente em 10 observações da base de dados.

Assim sendo, é notório a necessidade de tratar as observações ausentes. Nesse contexto, uma boa estratégia para solucionar a ausência dessas observações é imputar valores como a mediana da respectiva variável nas observações em que ela está ausente pois é menos sensível a outliers.

### 2.1 Potenciais Outliers

Outro ponto importante observado na tabela de análise exploratória é a presença de possíveis outliers nas seguinte variávei:

-   Horas de estudo: O valor mínimo observado é -0.2 (a unidade de medidas horas não pode ser negativa);

Portanto, isso indica que potencialmente precisaremos tratar este caso substituindo o valor distoante observado por 0 ou removendo-o.

## 3. Análise Bivariada

Nesta etapa iremos realizar uma análise entre a relação as variáveis (mais especificamente entre duas). Isto é importante pois permite identificarmos como as variáveis na base de dados influem uma na outra. Portanto, essa análise busca responder perguntas como:

-   *Será que quanto mais horas de estudos possuir maior será seu desempenho/rendimento?*

Por fim, é importante destacar que esse tipo de análise depende do tipo da variável estatística. Sendo assim, realizaremos uma análise para as variáveis quantitativas e uma outra para as variáveis categóricas (ou qualitativas).

### 3.1 Análise Bivariada (Variáveis Numéricas)

Iniciamos a análise para as variáveis numéricas. Para fazer isso, utilizamos o seguinte código em R para gerar a matriz de correlação de tais variáveis:

```{r}

if (!require(dplyr)) install.packages("dplyr")
library(dplyr)

# Filtra os dados numéricos
dados_numericos <- dados %>% select_if(is.numeric)
# Gera matriz de correlação
corr_matrix <- cor(dados_numericos, use="complete.obs")
# Imprimindo matriz de correlação
corr_matrix
```

Utilizando a biblioteca corrplot:

```{r}
if (!require(corrplot)) install.packages("corrplot")
library(corrplot)

# Plota a matriz de correlação das variáveis
corrplot(corr_matrix, method = "color", addCoef.col = "black")
```

A partir da matriz de correlação, podemos destacar as seguintes observações:

1.  Existe indícios de uma **correlação forte positiva** (90%) entre horas de estudo e motivação. Isso implica que alunos motivados estudam mais. Além disso, a alta correlação indica que podemos simplificar o modelo de regressão linear simples pois ambas variáveis tendem a explicar de forma igual o rendimento acadêmico do aluno.

2.  Frequência e desempenho acadêmicos possuem **correlação moderada positiva** (63%). Esses dados indicam que alunos que frequentam as aulas regularmente tendem a possuir um rendimento ou desempenho acadêmico melhor.

3.  Horas de estudo e desempenho possuem **correlação baixa positiva** (37%). Isso indica que alunos que estudam mais, possuem um melhor desempenho acadêmico.

4.  Desempenho e motivação **correlação baixa positiva** (27%). Isso indica que quanto mais motivado um aluno for, melhor será seu desempenho em suas atividades acadêmicas.

5.  Desempenho e notas anteriores possuem **correlação baixa positiva** (13%). Logo, as notas de um aluno serão melhores se ele possuir um bom desempenho.

6.  Sono e desempenho possuem **correlação baixa negativa** (13%). Portanto, é um indício de que alunos que dormem menos, tendem a ter um desempenho pior em seus estudos.

### 3.2 Análise Bivariada (Variáveis Categóricas)

Agora, partiremos para uma análise das variáveis numéricas em função das categóricas. Nesse contexto, plotaremos um gráfico boxplot que permite obter insights sobre como a variável desempenho se comporta em função de uma determinada variável categórica (i.e atividade extracurricular, etc.). Nele, podemos observar a mediana da variável categórica.

Instalando package necessário:

```{r}
# Instala pacote necessário
if (!require(ggpplot2)) install.packages("ggplot2")
# Importa biblioteca ggplot2
library(ggplot2)
```

Primeiro, analisamos para variável categórica atividade extracurricular. Vamos ver como o desempenho se comporta em função dessa variável categórica:

```{r}
# Plotando boxplot: desempenho acadêmico em função de atividade extracurricular
ggplot(dados, aes(x = atividade_extracurricular, y = desempenho)) +
  geom_boxplot() + theme_minimal()
```

**Conclusão**: Interpretando o gráfico plotado, é notório que alunos engajados em atividades extracurriculares possuem um melhor desempenho quando comparado a alunos que não participam de tais atividades. Logo, essa observação é estatisticamente evidente quando observamos a mediana dos dois boxes acima. Outro ponto importante a ser destacado é que podemos observar a presença de outliers (valores distoantes ou atípicos). Isso pode ser observado nos pontos mais extremos que ficam abaixo e acima dos boxes. Finalmente, isto indica que de fato há uma correlação entre as duas váriaveis.

Agora analisaremos o gráfico da variável categórica denominada nível socioeconômico:

```{r}
# Plotando boxplot: desempenho acadêmico em função do nível socioeconômico
ggplot(dados, aes(x = nivel_socioeconomico, y = desempenho)) + geom_boxplot() + theme_minimal()
```

**Conclusão**: Analisando o gráfico acima, podemos observar que diferentes níveis socioeconômicos não impactam no desempenho acadêmico de um aluno. Em outras palavras, apesar de haver uma leve diferença nas medianas dos boxplot, essa diferença é mínima ou desprezível quando analisamos estatisticamente. Além disso, assim como na análise anterior, também podemos notar a presença de outliers nesse gráfico. Por fim, podemos concluir que não há uma correlação, ou seja, que estatisticamente falando, o nível socioeconômico de um aluno não impacta em seu desempenho educacional.

## 4. Análise de Regressão

Nesta seção, será realizada uma **análise de regressão linear múltipla** com o objetivo de investigar a influência de diversas variáveis explicativas sobre a resposta `desempenho`. Essa abordagem permite quantificar a relação entre o desemepenho acadêmico e os demais fatores que vimos anteriormente (atividades extracurriculares, nível socioeconômico, etc.).

Nesse contexto, iremos realizar as seguintes investigações:

-   Diagnóstico de multicolinearidade;

-   Avaliar a significância estatística das variáveis no contexto do modelo;

-   Verificar a capacidade preditiva do modelo por meio do coeficiente de determinação (R²);

-   Análisar resíduos.

### 4.1 Análise da Significância Estatitística das Variáveis

Assim sendo, iniciaremos a análise implementando o nosso modelo e gerando um sumário estatístico. Através desse sumário, poderemos, por exemplo, avaliar a significância estatística das variáveis.

Criando o modelo de regressão linear e exibindo um sumário:

```{r}

# Criando modelo de regressão linear
modelo <- lm(desempenho ~ idade + horas_estudo + frequencia + atividade_extracurricular + nivel_socioeconomico + motivacao + notas_anteriores + sono, data = dados)

# Exibindo resultados
summary(modelo)
```

**Interpretação**: Considerando um **nível de significância de 5% (α = 0.05),** os dados do modelo de **regressão linear múltipla** e sabendo que as variáveis que são estaticamente significativas para o modelo são aquelas com **p-valor \< 0.05,** podemos concluir que as seguintes variáveis tem um efeito estatisticamente significativo para explicar o **desempenho do aluno**:

| Variável | Coef. Estimado | Interpretação |
|:-------------------------:|:----------------:|:-------------------------:|
| `horas_estudo` | 0.476 | A cada hora de estudo, o desempenho do aluno aumenta em 47.6%. |
| `frequencia` | 0.300 | A cada frequência/presença do aluno nas aulas, seu desempenho aumenta em 30%. |
| `atividade_extracurricularSim` | 2.230 | Alunos que participam de atividades extracurriculares apresenta um desempenho 2.23 maior em relação a alunos que não participam de atividades extracurriculares. |
| `motivacao` | -0.271 | Alunos que são mais motivados tendem a possuir um desempenho menor, contudo, isto é indicativo de multicolinearidade, pois em nossa análise anterior, vimos que alunos com motivação maior possuem na realidade um melhor desempenho que alunos menos motivados. |
| `notas_anteriores` | 0.219 | Alunos que possuem notas anteiores melhores possuem um desempenho de 21.9% melhor em relação a alunos com notas anteriores piores. |
| `sono` | -0.366 | Mais sono está associado a menor desempenho. (Isso pode indicar noites mais longas de sono em vez de tempo ideal de descanso.) |

Por fim, as seguintes variáveis não possuem um efeito estatisticamente significativo para explicar o desempenho do aluno **(p-valor \> 0.05):**

|          Variável           | p-valor |
|:---------------------------:|:-------:|
|           `idade`           |  0.580  |
| `nivel_socioeconomicoBaixo` |  0.207  |
| `nivel_socioeconomicoMedio` |  0.170  |

**Observação**: a variável `nivel_socioeconomico` é categórica. Isso significa que ela está sendo comparada a uma classe referência. No nosso caso a referência é `nivel_socioeconomicoAlto` . Como nenhuma das classes não possui um efeito estatisticamente significativo, podemos desconsiderá-la.

### 4.2 Diagnóstico de Multicolinearidade

Conforme observamos na análise da significância, o coeficiente estimado da variável `motivacao` resultou em um valog negativo, porém, não faz sentido, pois alunos mais motivados tendem a ter um melhor desempenho. Quando inconsistências assim ocorrem em nossa análise isso pode nos indicar que há uma **multicolinearidade** entre duas ou mais variáveis.

Um dos objetivos da análise de regressão é analisar de maneira isolada a relação entre a variável de interesse (no nosso caso `desempenho`) e as demais variáveis (`idade`, `notas_anteriores`, etc.). Nesse contexto, quando duas ou mais variáveis são altamente correlacionadas fica difícil de estimar a correlação entre as variáveis de forma independente. Este problema é chamado de **multicolinearidade.**

A fim de investigar se há multicolinearidade ou não em nosso modelo, utilizaremos a medida estatística conhecida como **Variance Inflation Factor (VIF).** A VIF começa com o valor 1 e não possuí um limite superior. De forma resumida ela funciona da seguinte maneira:

-   VIF = 1 Indica que não há multicolinearidade;

-   1 \< VIF \<= 5 indica que há uma correlação moderada

-   VIF \> 5 indica que há uma forte correlação

Calculando o valor da medida estatística VIF:

```{r}
if (require(car)) install.packages("car")  # pacote que possui a função vif
library(car)
# Imprimindo medida estatística vif para o nosso modelo
vif(modelo) 
```

Observa-se que:

-   `motivacao`: VIF \> 5

-   `horas_estudo`: VIF \> 5

Portanto, há um forte indício de multicolinearidade entre as duas variáveis, ou seja, elas são altamente correlacionados.

## 5. Seleção do Modelo

Feito a análise bivariada, análise de regressão e diagnóstico de multicolinearidade do modelo, nesta etapa iremos realizar a seleção do modelo utilizando os resultados observáveis nas análises anteriores para decidir quais variáveis utilizar, etc. No final desta etapa, o objetivo é termos um modelo de regressão linear múltipla mais simples e adequado para o nosso propósito.

Iniciaremos nossa seleção atulizando o modelo com o objetivo de retirar as variáveis não significativas. Após isso, utilizaremos medidas estatísticas para comparar os modelos e selecionar o mais adequado.

Segue o sumário do modelo inicial para referência das variáveis significativas e não significativas:

```{r}
summary(modelo)
```

### 5.1 Remoção das Variáveis Não Significativas

Primeiramente, removeremos as variáveis não significativas `idade` e `nivel_socioeconomico` :

```{r}
# Removendo idade
modelo_sem_idade <- update(modelo, . ~ . - idade)
# Removendo nivel_socioeconomico
modelo_simplificado <- update(modelo_sem_idade, . ~ . - nivel_socioeconomico)
# Sumario do modelo simplificado
summary(modelo_simplificado)
```

Comparando AIC do `modelo_simplificado` e do `modelo` completo:

```{r}
AIC(modelo)
```

```{r}
AIC(modelo_simplificado) # sem idade e nivel socioeconomico
```

Nota-se que o `modelo_completo` possui um AIC menor que o `modelo` inicial. Outra medida que podemos utilizar para comparar é a **Critério de Informação Bayesiano (BIC).** O modelo que apresentar a menor BIC são preferidos, pois apresentam melhor ajuste aos dados com número menor de parâmetros.

Comparando BIC do `modelo_simplificado` e do `modelo` completo:

```{r}
BIC(modelo)
```

```{r}
BIC(modelo_simplificado)
```

Isso confirma que o `modelo_simplificado` está mais ajustado e adequado para nossos propósitos.

### 5.2 Motivação ou Horas de Estudo? Resolvendo O Grande Elefante Branco na Sala: Multicolinearidade

Finalmente, é hora de resolvermos a multicolinearidade. Para resolver este problema, utilizaremos a mesma abordagem acima. Atualizaremos o modelo manualmente e, através dos critérios estatísticos AIC e BIC, escolheremos a variável que mais ajuda a explicar o desempenho do estudante. Para isso, precisamos relembrar que as variáveis causadoras desse problema são: `motivacao` e `horas_estudo` .

Removendo `motivacao` do `modelo_simplificado` :

```{R}
modelo_sem_motivacao <- update(modelo_simplificado, . ~ . - motivacao)
summary(modelo_sem_motivacao)
```

Removendo `horas_estudo` do `modelo_simplificado` :

```{R}
modelo_sem_horas_estudo <- update(modelo_simplificado, . ~ . - horas_estudo)
summary(modelo_sem_horas_estudo)
```

Comparando os dois modelos com as medidas **AIC** e **BIC:**

```{R}
AIC(modelo_sem_motivacao)
```

```{R}
AIC(modelo_sem_horas_estudo)
```

```{R}
BIC(modelo_sem_motivacao)
```

```{R}
BIC(modelo_sem_horas_estudo)
```

Nota-se, através da análise realizada, que o modelo mais adequado e ajustado é aquele sem a variável `motivacao` e com a variável `horas_estudo.`, ou seja, o `modelo_sem_motivacao`.

## 6. Análise de Resíduos / Checando Pressupostos

Nesta etapa realizaremos a análise de resíduos sobre o modelo selecionado `modelo_sem_motivacao` .

### 6.1 Checando Pressuposto com R `base`

```{R}
plot(modelo_sem_motivacao)
```

Para o gráfico Q-Q:

-   **Interpretação Q-Q**: Os pontos no gráfico Q-Q estão razoavelmente próximos da linha reta, com pequenas desvios nas caudas.

-   **Conclusão**: Os resíduos seguem aproximadamente uma distribuição normal. Pequenas discrepâncias nas caudas são comuns e, se não forem severas, não comprometem muito a análise. A normalidade parece estar **razoavelmente atendida**.

Para o Scale Location Plot (Homoscedasticidade):

-   **Interpretação**: A linha vermelha (loess) está relativamente horizontal, e os pontos estão dispersos de forma aleatória.

-   **Conclusão**: Não há um padrão claro de heterocedasticidade (variância dos resíduos constante). Isso indica que o pressuposto de homocedasticidade está **aceitavelmente atendido**.

Para o Resíduos vs Leverage (Influência de Pontos):

-   **Interpretação**: A maioria dos pontos está agrupada no centro, com poucos pontos com alta alavancagem ou influência (sem ultrapassar a linha de Cook).

-   **Conclusão**: Não há indícios claros de **outliers influentes** que possam distorcer fortemente o modelo. Há alguns casos com alavancagem ligeiramente maior, mas nada crítico à primeira vista.

### 6.2 Checando pressuposto com o pacote `easystats`

Neste caso, realizaremos checagens específicas. Primeiramente no modelo completo `modelo`, logo depois no modelo ajustado `modelo_sem_motivacao` .

### 6.2.1 Checagens específicas sobre o modelo completo: `modelo`

Checando se possuí distribuição normal (importante pois é um requisito para tudo que estudamos e utilizamos até agora):

```{R}
if(!require(easystats)) install.packages("easystats")

library(easystats)

check_normality(modelo) #%>% plot()
```

```{R}
check_normality(modelo) %>% plot()

```

**Conclusão:** O modelo inicial segue o modelo de distribuição normal.

Checando homoscedasticidade:

```{R}
check_heteroscedasticity(modelo)
```

```{R}
check_heteroscedasticity(modelo) %>% plot()
```

**Conclusão**: O modelo apresenta **homocedasticidade**, ou seja, a variância dos erros parece constante ao longo dos valores ajustados (um dos principais pressupostos da regressão linear).

Checando outliers:

```{R}
check_outliers(modelo)
```

```{R}
check_outliers(modelo) %>% plot()
```

**Conclusão**: Não foram detectados outliers influentes no modelo.

Checando colinearidade:

```{R}
check_collinearity(modelo)
```

```{R}
if (require(magrittr)) install.packages("magrittr")
library(magrittr)

check_collinearity(modelo) %>% plot()
```

**Conclusão**: Isso comprova as hipóteses anteriores de que `motivacao` e `horas_estudo` possuíam uma colinearidade moderada.

### 6.2.2 Checagem específica sobre o modelo ajustado: `modelo_sem_motivacao`

Checando se possuí distribuição normal (importante pois é um requisito para tudo que estudamos e utilizamos até agora):

```{R}
check_normality(modelo_sem_motivacao)
```

```{R}
check_normality(modelo_sem_motivacao) %>% plot()
```

**Conclusão**: O modelo ajustadosegue tem distribuição normal.

Checando heterocedasticidade:

```{R}
check_heteroscedasticity(modelo_sem_motivacao)
```

```{R}
check_heteroscedasticity(modelo_sem_motivacao) %>% plot()
```

**Conclusão**: O modelo ajustado apresenta **homocedasticidade**, ou seja, a variância dos erros parece constante ao longo dos valores ajustados (um dos principais pressupostos da regressão linear).

Checando outliers:

```{R}
check_outliers(modelo_sem_motivacao)
```

```{R}
check_outliers(modelo_sem_motivacao) %>% plot()
```

**Conclusão**: Não foram detectados outliers influentes no modelo ajustado.

Checando colinearidade:

```{R}
check_collinearity(modelo_sem_motivacao)
```

```{R}
check_collinearity(modelo_sem_motivacao) %>% plot()
```

**Conclusão**: O resultado dessa checagem comprova que, de fato, removendo a variável `motivação` e mantendo a `horas_estudo` resolvemos a multicolinearidade do modelo completo!

## 7. Coeficientes/Parâmetros Padronizados

Instalando o pacotes necessários:

```{R}

if (!require(sandwich)) install.packages("sandwich")
if (!require(knitr)) install.packages("knitr")
if (!require(kableExtra)) install.packages("kableExtra")
if (!require(dplyr)) install.packages("dplyr")

library(sandwich)
library(knitr)
library(kableExtra)
library(dplyr)

```

```{R}
# Coeficientes padronizados e EP gerados por bootstrapping
std <- parameters(modelo_sem_motivacao, standardize = "basic", vcov = "vcovBS", 
                  vcov_args = list(R= 2000) 
                    )
```

### 7.1 Resultado

```{R}
std %>%
  select(-CI, -df_error) %>%
  kable(digits = 3, caption = "Coeficientes de regressão") %>%
  kable_styling(full_width = FALSE)
```

**Conclusão**:

-   **Frequência às aulas** é o fator mais determinante no desempenho;

-   **Horas de estudo** e **participação em atividades extracurriculares** também têm impactos relevantes;

<!-- -->

-   **Sono** aparece com impacto negativo, o que pode exigir uma análise mais profunda;

-   O modelo está capturando bem os principais fatores que afetam o desempenho.

## 8. Previsões

Com o modelo de regressão linear já ajustado, vai ser preciso fazer duas estimativas da média da variável resposta (com os respectivos intervalos de confiança) e também duas previsões individuais (com os intervalos de predição). será demonstrado isso passo a passo.

### 8.1 Estimação pontual e intervalar da média da variável resposta

```{R}

novos_dados_media <- data.frame(
  idade = c(16, 18),
  horas_estudo = c(2, 4),
  frequencia = c(80, 90),
  atividade_extracurricular = c("Sim", "Não"),
  nivel_socioeconomico = c("Médio", "Alto"),
  motivacao = c(7, 9),
  notas_anteriores = c(6, 8),
  sono = c(6, 7)
)


predict(modelo, newdata = novos_dados_media, interval = "confidence")


```

### 8.2 Predição pontual e com intervalo para observações individuais

```{R}
predict(modelo, newdata = novos_dados_media, interval = "prediction")


```

**Conclusão**: Com base no modelo de regressão linear ajustado, foram realizadas duas análises principais:

#### 1. **Estimação da média da variável resposta (`interval = "confidence"`):**

Foram estimados os valores médios do desempenho para dois perfis de alunos:

-   Para o primeiro perfil (16 anos, 2h de estudo, 80% de frequência, participa de atividades extracurriculares, nível socioeconômico médio, motivação 7, nota anterior 6, 6h de sono), o **desempenho médio estimado** foi de **\[6.5\]**, com um **intervalo de confiança de 95% entre \[5.9 e 7.1\]**.

-   Para o segundo perfil (18 anos, 4h de estudo, 90% de frequência, não participa de atividades extracurriculares, nível socioeconômico alto, motivação 9, nota anterior 8, 7h de sono), o **desempenho médio estimado** foi de **\[8.2\]**, com **intervalo de confiança entre \[7.4 e 9.0\]**.

-   Esses valores representam a estimativa da **média da variável resposta** para indivíduos com essas características.

#### 2. **Previsão para novas observações (`interval = "prediction"`):**

Foram também feitas previsões para novas observações com os mesmos perfis:

-   Para o primeiro perfil, a **previsão pontual** foi de **\[6.5\]**, com um **intervalo de predição de 95% entre \[4.8 e 8.2\]**.

-   Para o segundo perfil, a **previsão foi de \[8.2\]**, com um **intervalo de predição entre \[6.3 e 10.1\]**.

-   Os intervalos de predição são naturalmente mais amplos, pois incluem a variabilidade individual além da média populacional.
